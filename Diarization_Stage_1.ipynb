{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; font-size: 36px; color: #3498db; font-weight: bold;\">Prosody Tools</h1>\n",
    "\n",
    "## <h2 style=\"text-align: center; font-size: 28px; color: #2ecc71; font-weight: bold;\">Prosody Diarization Tool</h2>\n",
    "### <h3 style=\"text-align: center; font-size: 24px; color: #e74c3c; font-family: 'Arial', sans-serif; font-weight: bold;\">Stage 1</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "\n",
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "import torchvision\n",
    "import torchaudio\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from pyannote.audio.pipelines.utils.hook import ProgressHook\n",
    "from pydub import AudioSegment\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Running on GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyannote pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "  \"pyannote/speaker-diarization-3.1\",\n",
    "  use_auth_token=\"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\")\n",
    "\n",
    "#https://huggingface.co/pyannote/speaker-diarization-3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the RTTM files\n",
    "## Stage 0, number of speakers are unlimitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPRA_1_001.wav  Done...\n",
      "EXPRA_1_002.wav  Done...\n",
      "EXPRA_1_003.wav  Done...\n",
      "EXPRA_3_012.wav  Done...\n",
      "PBN_114.wav  Done...\n",
      "PBN_166.wav  Done...\n"
     ]
    }
   ],
   "source": [
    "# Save RTTMs\n",
    "\n",
    "import os\n",
    "from pyannote.audio.pipelines import SpeakerDiarization\n",
    "\n",
    "# diarization pipeline\n",
    "diarization_pipeline = pipeline\n",
    "\n",
    "# Path to WAV files\n",
    "input_dir = r\".\\Database\\0.Interviews\\wav\\stage_1\"\n",
    "\n",
    "# Create output if it doesn't exist\n",
    "output_dir = r\".\\Database\\1.rttms\\stage_1\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterateall WAV files in the input\n",
    "for file_name in os.listdir(input_dir):\n",
    "    if file_name.endswith(\".wav\"):\n",
    "        # Construct the full path to the WAV file\n",
    "        wav_file_path = os.path.join(input_dir, file_name)\n",
    "\n",
    "        # Perform diarization\n",
    "        #waveform, sample_rate = torchaudio.load(wav_file_path)\n",
    "        #diarization = pipeline({\"waveform\": waveform, \"sample_rate\": sample_rate})\n",
    "\n",
    "        #diarization = pipeline(wav_file_path, num_speakers=2)\n",
    "        diarization = pipeline(wav_file_path)\n",
    " \n",
    "        \n",
    "        # Construct output RTTM file\n",
    "        rttm_file_path = os.path.join(output_dir, f\"{os.path.splitext(file_name)[0]}.rttm\")\n",
    "\n",
    "        # diarization output RTTM format\n",
    "        with open(rttm_file_path, \"w\") as rttm_file:\n",
    "            diarization.write_rttm(rttm_file)\n",
    "            print (file_name, ' Done...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the interview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Interview_ID</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Start</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Speaker_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>EXPRA_1_001</td>\n",
       "      <td>1</td>\n",
       "      <td>2.073</td>\n",
       "      <td>16.065</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>EXPRA_1_001</td>\n",
       "      <td>1</td>\n",
       "      <td>2.107</td>\n",
       "      <td>0.236</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>EXPRA_1_001</td>\n",
       "      <td>1</td>\n",
       "      <td>18.982</td>\n",
       "      <td>0.017</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>EXPRA_1_001</td>\n",
       "      <td>1</td>\n",
       "      <td>18.998</td>\n",
       "      <td>0.624</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>EXPRA_1_001</td>\n",
       "      <td>1</td>\n",
       "      <td>20.568</td>\n",
       "      <td>1.029</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>PBN_166</td>\n",
       "      <td>1</td>\n",
       "      <td>1149.387</td>\n",
       "      <td>0.017</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>PBN_166</td>\n",
       "      <td>1</td>\n",
       "      <td>1152.070</td>\n",
       "      <td>2.565</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>PBN_166</td>\n",
       "      <td>1</td>\n",
       "      <td>1157.268</td>\n",
       "      <td>0.489</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>PBN_166</td>\n",
       "      <td>1</td>\n",
       "      <td>1159.023</td>\n",
       "      <td>0.287</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>SPEAKER</td>\n",
       "      <td>PBN_166</td>\n",
       "      <td>1</td>\n",
       "      <td>1167.173</td>\n",
       "      <td>12.150</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1678 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Type Interview_ID Channel     Start  Duration  Speaker_ID\n",
       "0     SPEAKER  EXPRA_1_001       1     2.073    16.065  SPEAKER_00\n",
       "1     SPEAKER  EXPRA_1_001       1     2.107     0.236  SPEAKER_01\n",
       "2     SPEAKER  EXPRA_1_001       1    18.982     0.017  SPEAKER_01\n",
       "3     SPEAKER  EXPRA_1_001       1    18.998     0.624  SPEAKER_00\n",
       "4     SPEAKER  EXPRA_1_001       1    20.568     1.029  SPEAKER_00\n",
       "...       ...          ...     ...       ...       ...         ...\n",
       "1673  SPEAKER      PBN_166       1  1149.387     0.017  SPEAKER_00\n",
       "1674  SPEAKER      PBN_166       1  1152.070     2.565  SPEAKER_00\n",
       "1675  SPEAKER      PBN_166       1  1157.268     0.489  SPEAKER_00\n",
       "1676  SPEAKER      PBN_166       1  1159.023     0.287  SPEAKER_00\n",
       "1677  SPEAKER      PBN_166       1  1167.173    12.150  SPEAKER_00\n",
       "\n",
       "[1678 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# directory RTTM files\n",
    "rttm_dir = r\".\\Database\\1.rttms\\Stage_1\"\n",
    "\n",
    "columns = [\"Type\", \"Interview_ID\", \"Channel\", \"Start\", \"Duration\", \"NA1\", \"NA2\", \"Speaker_ID\", \"NA3\", \"NA4\"]\n",
    "\n",
    "# combined data from all RTTM files\n",
    "combined_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# RTTM files in the directory\n",
    "for file_name in os.listdir(rttm_dir):\n",
    "    if file_name.endswith(\".rttm\"):\n",
    "        # path to the RTTM file\n",
    "        rttm_file_path = os.path.join(rttm_dir, file_name)\n",
    "\n",
    "        # Read the RTTM file into a DataFrame\n",
    "        rttm_df = pd.read_csv(rttm_file_path, sep=\" \", header=None, names=columns)\n",
    "\n",
    "        # Append RTTM file to the combined DataFrame\n",
    "        combined_df = pd.concat([combined_df, rttm_df], ignore_index=True)\n",
    "\n",
    "# Drop the columns 'NA1', 'NA2', 'NA3', and 'NA4' from the DataFrame\n",
    "combined_df = combined_df.drop(columns=['NA1', 'NA2', 'NA3', 'NA4'])\n",
    "\n",
    "combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SPEAKER_00', 'SPEAKER_01', 'SPEAKER_02'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['Speaker_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Interview_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# split based on start and duration\n",
    "def split_audio(input_path, output_path, start, duration, filename):\n",
    "    sound = AudioSegment.from_wav(input_path)\n",
    "    split_sound = sound[start*1000:(start+duration)*1000]  # Pydub in milliseconds\n",
    "    split_sound.export(os.path.join(output_path, filename), format=\"wav\")\n",
    "\n",
    "df = combined_df\n",
    "\n",
    "input_dir = r\".\\Database\\0.Interviews\\wav\\Stage_1\"\n",
    "output_dir = r\".\\Database\\2.Speaker_Parts\\Stage_1\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "i = 0\n",
    "# each row in df\n",
    "for index, row in df.iterrows():\n",
    "    interview_id = row['Interview_ID']\n",
    "    speaker_id = row['Speaker_ID']\n",
    "    start = row['Start']\n",
    "    duration = row['Duration']\n",
    "    filename = f\"{interview_id}_{speaker_id}_{i}.wav\"\n",
    "    input_path = os.path.join(input_dir, f\"{interview_id}.wav\")\n",
    "    output_path = os.path.join(output_dir, speaker_id)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    split_audio(input_path, output_path, start, duration, filename)\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join the Speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Function to concatenate wav files with a gap\n",
    "def concatenate_wav_files_with_gap(directory, output, gap_duration=0.1):\n",
    "    # Store wave file objects\n",
    "    wave_files = {}\n",
    "\n",
    "    # List files in directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            # Prefix based on the first two parts of the filename\n",
    "            if (filename.split('_')[0] == 'PBN'):\n",
    "                prefix = '_'.join(filename.split('_')[:2])\n",
    "            elif (filename.split('_')[0] == 'EXPRA'):\n",
    "                prefix = '_'.join(filename.split('_')[:3])\n",
    "            else:\n",
    "                print('Name ERROR..............')\n",
    "                continue\n",
    "\n",
    "            # Append filename to the corresponding prefix list\n",
    "            if prefix in wave_files:\n",
    "                wave_files[prefix].append(filename)\n",
    "            else:\n",
    "                wave_files[prefix] = [filename]\n",
    "\n",
    "    # Concatenate WAV files with the specified gap\n",
    "    for prefix, files in wave_files.items():\n",
    "        # Sort the files based on the last numeric part in the filename\n",
    "        files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "        # Create an empty AudioSegment to combine files\n",
    "        combined = AudioSegment.silent(duration=0)  # Start with zero duration\n",
    "\n",
    "        # Iterate through each file and concatenate with silence gaps\n",
    "        for file in files:\n",
    "            # Load each WAV file\n",
    "            current_segment = AudioSegment.from_wav(os.path.join(directory, file))\n",
    "            \n",
    "            # Add a 0.2-second silent gap between segments\n",
    "            combined += current_segment + AudioSegment.silent(duration=gap_duration * 1000)\n",
    "\n",
    "        # Export the combined segment to the output directory\n",
    "        output_filename = os.path.join(output, f\"{prefix}_{os.path.basename(directory)}.wav\")\n",
    "        combined.export(output_filename, format=\"wav\")\n",
    "        print(f\"Combined file saved: {output_filename}\")\n",
    "\n",
    "# Define directories and speakers\n",
    "if __name__ == \"__main__\":\n",
    "########### you have to check the number of speakers in  'combined_df['Speaker_ID'].unique()' ####################\n",
    "    speakers = [f\"SPEAKER_{str(i).zfill(2)}\" for i in range(5)]  # Adjust range as needed (e.g., range(10) for 10 speakers)\n",
    "    stage = \"Stage_1\"\n",
    "    \n",
    "    for speaker in speakers:\n",
    "        directory = rf\".\\Database\\2.Speaker_Parts\\{stage}\\{speaker}\"\n",
    "        output = rf\".\\Database\\3.Speaker_Combined\\{stage}\\{speaker}\"\n",
    "        # Create the output directory if it does not exist\n",
    "        os.makedirs(output, exist_ok=True)\n",
    "\n",
    "        print(f\"Processing {speaker}...\")\n",
    "        # Run the concatenation function with the desired gap duration\n",
    "        concatenate_wav_files_with_gap(directory, output, gap_duration=0.1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kali-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
